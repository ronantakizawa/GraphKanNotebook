{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tgPLdkzEifhe",
        "outputId": "0a2c7349-a083-4b34-c513-c7c6ac135e06"
      },
      "id": "tgPLdkzEifhe",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "258e3394",
      "metadata": {
        "id": "258e3394"
      },
      "outputs": [],
      "source": [
        "# kan_layer.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "class NaiveFourierKANLayer(nn.Module):\n",
        "    def __init__(self, inputdim, outdim, gridsize=300, addbias=True):\n",
        "        super(NaiveFourierKANLayer, self).__init__()\n",
        "        self.gridsize = gridsize\n",
        "        self.addbias = addbias\n",
        "        self.inputdim = inputdim\n",
        "        self.outdim = outdim\n",
        "\n",
        "        self.fouriercoeffs = nn.Parameter(torch.randn(2, outdim, inputdim, gridsize) /\n",
        "                                          (np.sqrt(inputdim) * np.sqrt(self.gridsize)))\n",
        "        if self.addbias:\n",
        "            self.bias = nn.Parameter(torch.zeros(1, outdim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        xshp = x.shape\n",
        "        outshape = xshp[0:-1] + (self.outdim,)\n",
        "        x = x.view(-1, self.inputdim)\n",
        "        k = torch.reshape(torch.arange(1, self.gridsize + 1, device=x.device), (1, 1, 1, self.gridsize))\n",
        "        xrshp = x.view(x.shape[0], 1, x.shape[1], 1)\n",
        "        c = torch.cos(k * xrshp)\n",
        "        s = torch.sin(k * xrshp)\n",
        "        c = torch.reshape(c, (1, x.shape[0], x.shape[1], self.gridsize))\n",
        "        s = torch.reshape(s, (1, x.shape[0], x.shape[1], self.gridsize))\n",
        "        y = torch.einsum(\"dbik,djik->bj\", torch.concat([c, s], axis=0), self.fouriercoeffs)\n",
        "        if self.addbias:\n",
        "            y += self.bias\n",
        "        y = y.view(outshape)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8f3be5a0",
      "metadata": {
        "id": "8f3be5a0"
      },
      "outputs": [],
      "source": [
        "# utils.py\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "def index_to_mask(index, size):\n",
        "    mask = torch.zeros(size, dtype=torch.bool, device=index.device)\n",
        "    mask[index] = 1\n",
        "    return mask\n",
        "\n",
        "def random_disassortative_splits(labels, num_classes, trn_percent=0.6, val_percent=0.2):\n",
        "    labels, num_classes = labels.cpu(), num_classes.cpu().numpy()\n",
        "    indices = []\n",
        "    for i in range(num_classes):\n",
        "        index = torch.nonzero((labels == i)).view(-1)\n",
        "        index = index[torch.randperm(index.size(0))]\n",
        "        indices.append(index)\n",
        "\n",
        "    percls_trn = int(round(trn_percent * (labels.size()[0] / num_classes)))\n",
        "    val_lb = int(round(val_percent * labels.size()[0]))\n",
        "    train_index = torch.cat([i[:percls_trn] for i in indices], dim=0)\n",
        "\n",
        "    rest_index = torch.cat([i[percls_trn:] for i in indices], dim=0)\n",
        "    rest_index = rest_index[torch.randperm(rest_index.size(0))]\n",
        "\n",
        "    train_mask = index_to_mask(train_index, size=labels.size()[0])\n",
        "    val_mask = index_to_mask(rest_index[:val_lb], size=labels.size()[0])\n",
        "    test_mask = index_to_mask(rest_index[val_lb:], size=labels.size()[0])\n",
        "\n",
        "    return train_mask, val_mask, test_mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7e45acb1",
      "metadata": {
        "id": "7e45acb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250d2bf8-837f-4848-8e01-717e4947c32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run experiments on Cora dataset\n",
            "Epoch: 0000, Trn_loss: 2.1050, Trn_acc: 0.1464, Val_acc: 0.0387, Test_acc: 0.0328\n",
            "Epoch: 0001, Trn_loss: 63.5351, Trn_acc: 0.2010, Val_acc: 0.1679, Test_acc: 0.1724\n",
            "Epoch: 0002, Trn_loss: 96.1933, Trn_acc: 0.1522, Val_acc: 0.0498, Test_acc: 0.0640\n",
            "Epoch: 0003, Trn_loss: 123.6806, Trn_acc: 0.1490, Val_acc: 0.1052, Test_acc: 0.1018\n",
            "Epoch: 0004, Trn_loss: 127.6281, Trn_acc: 0.1496, Val_acc: 0.1513, Test_acc: 0.1560\n",
            "Epoch: 0005, Trn_loss: 79.1536, Trn_acc: 0.2023, Val_acc: 0.1605, Test_acc: 0.1626\n",
            "Epoch: 0006, Trn_loss: 82.2540, Trn_acc: 0.2132, Val_acc: 0.1236, Test_acc: 0.1166\n",
            "Epoch: 0007, Trn_loss: 83.4842, Trn_acc: 0.2261, Val_acc: 0.2786, Test_acc: 0.2611\n",
            "Epoch: 0008, Trn_loss: 57.1321, Trn_acc: 0.3205, Val_acc: 0.6476, Test_acc: 0.6371\n",
            "Epoch: 0009, Trn_loss: 56.0608, Trn_acc: 0.3359, Val_acc: 0.6863, Test_acc: 0.6519\n",
            "Epoch: 0010, Trn_loss: 53.3311, Trn_acc: 0.3911, Val_acc: 0.5812, Test_acc: 0.6026\n",
            "Epoch: 0011, Trn_loss: 44.7101, Trn_acc: 0.5106, Val_acc: 0.3561, Test_acc: 0.3645\n",
            "Epoch: 0012, Trn_loss: 45.0031, Trn_acc: 0.4515, Val_acc: 0.3469, Test_acc: 0.3383\n",
            "Epoch: 0013, Trn_loss: 41.8176, Trn_acc: 0.5286, Val_acc: 0.2399, Test_acc: 0.2414\n",
            "Epoch: 0014, Trn_loss: 46.8123, Trn_acc: 0.4239, Val_acc: 0.2583, Test_acc: 0.2529\n",
            "Epoch: 0015, Trn_loss: 38.6633, Trn_acc: 0.4477, Val_acc: 0.4502, Test_acc: 0.4499\n",
            "Epoch: 0016, Trn_loss: 19.3392, Trn_acc: 0.5960, Val_acc: 0.7140, Test_acc: 0.7258\n",
            "Epoch: 0017, Trn_loss: 8.7811, Trn_acc: 0.7065, Val_acc: 0.8579, Test_acc: 0.8473\n",
            "Epoch: 0018, Trn_loss: 5.3677, Trn_acc: 0.7592, Val_acc: 0.8672, Test_acc: 0.8522\n",
            "Epoch: 0019, Trn_loss: 10.0079, Trn_acc: 0.7225, Val_acc: 0.8247, Test_acc: 0.7750\n",
            "Epoch: 0020, Trn_loss: 14.8944, Trn_acc: 0.6924, Val_acc: 0.8026, Test_acc: 0.7586\n",
            "Epoch: 0021, Trn_loss: 15.8711, Trn_acc: 0.6898, Val_acc: 0.7970, Test_acc: 0.7718\n",
            "Epoch: 0022, Trn_loss: 13.7753, Trn_acc: 0.7001, Val_acc: 0.8007, Test_acc: 0.7635\n",
            "Epoch: 0023, Trn_loss: 11.8646, Trn_acc: 0.7013, Val_acc: 0.7989, Test_acc: 0.7718\n",
            "Epoch: 0024, Trn_loss: 10.2133, Trn_acc: 0.7026, Val_acc: 0.8081, Test_acc: 0.7964\n",
            "Epoch: 0025, Trn_loss: 6.9040, Trn_acc: 0.7681, Val_acc: 0.8487, Test_acc: 0.8325\n",
            "Epoch: 0026, Trn_loss: 3.8279, Trn_acc: 0.8574, Val_acc: 0.8672, Test_acc: 0.8571\n",
            "Epoch: 0027, Trn_loss: 2.3483, Trn_acc: 0.8985, Val_acc: 0.8672, Test_acc: 0.8555\n",
            "Epoch: 0028, Trn_loss: 1.8487, Trn_acc: 0.9171, Val_acc: 0.8469, Test_acc: 0.8473\n",
            "Epoch: 0029, Trn_loss: 1.9933, Trn_acc: 0.9191, Val_acc: 0.8173, Test_acc: 0.8309\n",
            "Epoch: 0030, Trn_loss: 2.5260, Trn_acc: 0.9094, Val_acc: 0.7878, Test_acc: 0.8079\n",
            "Epoch: 0031, Trn_loss: 3.0725, Trn_acc: 0.9011, Val_acc: 0.7804, Test_acc: 0.7898\n",
            "Epoch: 0032, Trn_loss: 3.5288, Trn_acc: 0.8882, Val_acc: 0.7694, Test_acc: 0.7816\n",
            "Epoch: 0033, Trn_loss: 3.7754, Trn_acc: 0.8838, Val_acc: 0.7731, Test_acc: 0.7767\n",
            "Epoch: 0034, Trn_loss: 3.7401, Trn_acc: 0.8844, Val_acc: 0.7786, Test_acc: 0.7767\n",
            "Epoch: 0035, Trn_loss: 3.4457, Trn_acc: 0.8882, Val_acc: 0.7915, Test_acc: 0.7947\n",
            "Epoch: 0036, Trn_loss: 2.9577, Trn_acc: 0.8953, Val_acc: 0.8081, Test_acc: 0.8062\n",
            "Epoch: 0037, Trn_loss: 2.4130, Trn_acc: 0.9165, Val_acc: 0.8266, Test_acc: 0.8194\n",
            "Epoch: 0038, Trn_loss: 1.9312, Trn_acc: 0.9300, Val_acc: 0.8358, Test_acc: 0.8276\n",
            "Epoch: 0039, Trn_loss: 1.4921, Trn_acc: 0.9403, Val_acc: 0.8487, Test_acc: 0.8358\n",
            "Epoch: 0040, Trn_loss: 1.1563, Trn_acc: 0.9512, Val_acc: 0.8579, Test_acc: 0.8424\n",
            "Epoch: 0041, Trn_loss: 0.9369, Trn_acc: 0.9589, Val_acc: 0.8542, Test_acc: 0.8522\n",
            "Epoch: 0042, Trn_loss: 0.8023, Trn_acc: 0.9589, Val_acc: 0.8635, Test_acc: 0.8654\n",
            "Epoch: 0043, Trn_loss: 0.7071, Trn_acc: 0.9634, Val_acc: 0.8690, Test_acc: 0.8686\n",
            "Epoch: 0044, Trn_loss: 0.6690, Trn_acc: 0.9634, Val_acc: 0.8690, Test_acc: 0.8686\n",
            "Epoch: 0045, Trn_loss: 0.6713, Trn_acc: 0.9647, Val_acc: 0.8690, Test_acc: 0.8621\n",
            "Epoch: 0046, Trn_loss: 0.6874, Trn_acc: 0.9621, Val_acc: 0.8690, Test_acc: 0.8588\n",
            "Epoch: 0047, Trn_loss: 0.6983, Trn_acc: 0.9640, Val_acc: 0.8616, Test_acc: 0.8473\n",
            "Epoch: 0048, Trn_loss: 0.6891, Trn_acc: 0.9640, Val_acc: 0.8598, Test_acc: 0.8391\n",
            "Epoch: 0049, Trn_loss: 0.6518, Trn_acc: 0.9660, Val_acc: 0.8542, Test_acc: 0.8358\n",
            "Epoch: 0050, Trn_loss: 0.5922, Trn_acc: 0.9666, Val_acc: 0.8561, Test_acc: 0.8374\n",
            "Epoch: 0051, Trn_loss: 0.5238, Trn_acc: 0.9711, Val_acc: 0.8542, Test_acc: 0.8407\n",
            "Epoch: 0052, Trn_loss: 0.4554, Trn_acc: 0.9750, Val_acc: 0.8506, Test_acc: 0.8424\n",
            "Epoch: 0053, Trn_loss: 0.3858, Trn_acc: 0.9762, Val_acc: 0.8506, Test_acc: 0.8456\n",
            "Epoch: 0054, Trn_loss: 0.3210, Trn_acc: 0.9794, Val_acc: 0.8506, Test_acc: 0.8407\n",
            "Epoch: 0055, Trn_loss: 0.2656, Trn_acc: 0.9827, Val_acc: 0.8487, Test_acc: 0.8374\n",
            "Epoch: 0056, Trn_loss: 0.2164, Trn_acc: 0.9839, Val_acc: 0.8542, Test_acc: 0.8407\n",
            "Epoch: 0057, Trn_loss: 0.1820, Trn_acc: 0.9839, Val_acc: 0.8561, Test_acc: 0.8440\n",
            "Epoch: 0058, Trn_loss: 0.1603, Trn_acc: 0.9839, Val_acc: 0.8561, Test_acc: 0.8473\n",
            "Epoch: 0059, Trn_loss: 0.1493, Trn_acc: 0.9878, Val_acc: 0.8579, Test_acc: 0.8489\n",
            "Epoch: 0060, Trn_loss: 0.1392, Trn_acc: 0.9891, Val_acc: 0.8579, Test_acc: 0.8506\n",
            "Epoch: 0061, Trn_loss: 0.1270, Trn_acc: 0.9897, Val_acc: 0.8579, Test_acc: 0.8506\n",
            "Epoch: 0062, Trn_loss: 0.1144, Trn_acc: 0.9904, Val_acc: 0.8579, Test_acc: 0.8489\n",
            "Epoch: 0063, Trn_loss: 0.1044, Trn_acc: 0.9910, Val_acc: 0.8561, Test_acc: 0.8489\n",
            "Epoch: 0064, Trn_loss: 0.0960, Trn_acc: 0.9910, Val_acc: 0.8524, Test_acc: 0.8456\n",
            "Epoch: 0065, Trn_loss: 0.0881, Trn_acc: 0.9923, Val_acc: 0.8506, Test_acc: 0.8456\n",
            "Epoch: 0066, Trn_loss: 0.0802, Trn_acc: 0.9936, Val_acc: 0.8506, Test_acc: 0.8440\n",
            "Epoch: 0067, Trn_loss: 0.0715, Trn_acc: 0.9942, Val_acc: 0.8506, Test_acc: 0.8440\n",
            "Epoch: 0068, Trn_loss: 0.0647, Trn_acc: 0.9942, Val_acc: 0.8487, Test_acc: 0.8440\n",
            "Epoch: 0069, Trn_loss: 0.0570, Trn_acc: 0.9955, Val_acc: 0.8487, Test_acc: 0.8424\n",
            "Epoch: 0070, Trn_loss: 0.0510, Trn_acc: 0.9961, Val_acc: 0.8487, Test_acc: 0.8424\n",
            "Epoch: 0071, Trn_loss: 0.0488, Trn_acc: 0.9961, Val_acc: 0.8487, Test_acc: 0.8424\n",
            "Epoch: 0072, Trn_loss: 0.0459, Trn_acc: 0.9955, Val_acc: 0.8487, Test_acc: 0.8440\n",
            "Epoch: 0073, Trn_loss: 0.0425, Trn_acc: 0.9949, Val_acc: 0.8506, Test_acc: 0.8440\n",
            "Epoch: 0074, Trn_loss: 0.0392, Trn_acc: 0.9942, Val_acc: 0.8506, Test_acc: 0.8440\n",
            "Epoch: 0075, Trn_loss: 0.0353, Trn_acc: 0.9949, Val_acc: 0.8506, Test_acc: 0.8440\n",
            "Epoch: 0076, Trn_loss: 0.0307, Trn_acc: 0.9949, Val_acc: 0.8506, Test_acc: 0.8456\n",
            "Epoch: 0077, Trn_loss: 0.0254, Trn_acc: 0.9968, Val_acc: 0.8524, Test_acc: 0.8489\n",
            "Epoch: 0078, Trn_loss: 0.0203, Trn_acc: 0.9968, Val_acc: 0.8524, Test_acc: 0.8489\n",
            "Epoch: 0079, Trn_loss: 0.0165, Trn_acc: 0.9968, Val_acc: 0.8524, Test_acc: 0.8489\n",
            "Epoch: 0080, Trn_loss: 0.0144, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0081, Trn_loss: 0.0124, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0082, Trn_loss: 0.0103, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0083, Trn_loss: 0.0082, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0084, Trn_loss: 0.0066, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0085, Trn_loss: 0.0056, Trn_acc: 0.9974, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0086, Trn_loss: 0.0058, Trn_acc: 0.9981, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0087, Trn_loss: 0.0064, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0088, Trn_loss: 0.0063, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8489\n",
            "Epoch: 0089, Trn_loss: 0.0057, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0090, Trn_loss: 0.0047, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8456\n",
            "Epoch: 0091, Trn_loss: 0.0041, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0092, Trn_loss: 0.0043, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0093, Trn_loss: 0.0048, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0094, Trn_loss: 0.0048, Trn_acc: 0.9987, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0095, Trn_loss: 0.0043, Trn_acc: 0.9987, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0096, Trn_loss: 0.0036, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0097, Trn_loss: 0.0035, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0098, Trn_loss: 0.0036, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0099, Trn_loss: 0.0036, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0100, Trn_loss: 0.0034, Trn_acc: 0.9987, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0101, Trn_loss: 0.0030, Trn_acc: 0.9987, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0102, Trn_loss: 0.0029, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0103, Trn_loss: 0.0029, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0104, Trn_loss: 0.0028, Trn_acc: 0.9981, Val_acc: 0.8524, Test_acc: 0.8473\n",
            "Epoch: 0105, Trn_loss: 0.0026, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0106, Trn_loss: 0.0024, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0107, Trn_loss: 0.0024, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0108, Trn_loss: 0.0023, Trn_acc: 0.9981, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0109, Trn_loss: 0.0021, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0110, Trn_loss: 0.0020, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0111, Trn_loss: 0.0019, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0112, Trn_loss: 0.0019, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0113, Trn_loss: 0.0018, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0114, Trn_loss: 0.0017, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0115, Trn_loss: 0.0016, Trn_acc: 0.9987, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0116, Trn_loss: 0.0016, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0117, Trn_loss: 0.0016, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0118, Trn_loss: 0.0015, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0119, Trn_loss: 0.0014, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0120, Trn_loss: 0.0014, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0121, Trn_loss: 0.0014, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0122, Trn_loss: 0.0014, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0123, Trn_loss: 0.0013, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0124, Trn_loss: 0.0013, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0125, Trn_loss: 0.0013, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0126, Trn_loss: 0.0013, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0127, Trn_loss: 0.0012, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0128, Trn_loss: 0.0012, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8473\n",
            "Epoch: 0129, Trn_loss: 0.0012, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0130, Trn_loss: 0.0012, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0131, Trn_loss: 0.0012, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0132, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0133, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0134, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0135, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0136, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0137, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0138, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0139, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0140, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0141, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0142, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0143, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0144, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0145, Trn_loss: 0.0011, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0146, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0147, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0148, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0149, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0150, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0151, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0152, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0153, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0154, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0155, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0156, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0157, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0158, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0159, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0160, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0161, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0162, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0163, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0164, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0165, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0166, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0167, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0168, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0169, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0170, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0171, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0172, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0173, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0174, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0175, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0176, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0177, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0178, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0179, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0180, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0181, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0182, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0183, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0184, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0185, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0186, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0187, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0188, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0189, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0190, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0191, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0192, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0193, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0194, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0195, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0196, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0197, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0198, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0199, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0200, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0201, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0202, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0203, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0204, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0205, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0206, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0207, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0208, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0209, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0210, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0211, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0212, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0213, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0214, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0215, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0216, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0217, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0218, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0219, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0220, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0221, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0222, Trn_loss: 0.0010, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0223, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0224, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0225, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0226, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0227, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0228, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0229, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0230, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0231, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0232, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8561, Test_acc: 0.8456\n",
            "Epoch: 0233, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0234, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0235, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0236, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0237, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0238, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0239, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0240, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0241, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0242, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0243, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0244, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0245, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0246, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0247, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0248, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0249, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0250, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0251, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0252, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0253, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0254, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0255, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0256, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0257, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0258, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0259, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0260, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0261, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0262, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0263, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0264, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0265, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0266, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0267, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0268, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0269, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0270, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0271, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0272, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0273, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0274, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0275, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0276, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0277, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0278, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0279, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0280, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0281, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0282, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0283, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0284, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0285, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0286, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0287, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0288, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0289, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0290, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0291, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0292, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0293, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0294, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0295, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0296, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0297, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0298, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0299, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0300, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0301, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0302, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0303, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0304, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0305, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0306, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0307, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0308, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0309, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0310, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0311, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0312, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0313, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0314, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0315, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0316, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0317, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0318, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0319, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0320, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0321, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0322, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0323, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0324, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0325, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0326, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0327, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0328, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0329, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0330, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0331, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0332, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0333, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0334, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0335, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0336, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0337, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0338, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0339, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0340, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0341, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0342, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0343, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0344, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0345, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0346, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0347, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0348, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0349, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0350, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0351, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0352, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0353, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0354, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0355, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0356, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0357, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0358, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0359, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0360, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0361, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0362, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0363, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0364, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0365, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0366, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0367, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0368, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0369, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0370, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0371, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0372, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0373, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0374, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0375, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0376, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0377, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0378, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0379, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0380, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0381, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0382, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0383, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0384, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0385, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0386, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0387, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0388, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0389, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0390, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0391, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0392, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0393, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0394, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0395, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0396, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0397, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0398, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0399, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0400, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0401, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0402, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0403, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0404, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0405, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0406, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0407, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0408, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0409, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0410, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0411, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0412, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0413, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0414, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0415, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0416, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0417, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0418, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0419, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0420, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0421, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0422, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0423, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0424, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0425, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0426, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0427, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0428, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0429, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0430, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0431, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0432, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0433, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0434, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0435, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0436, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0437, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0438, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0439, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0440, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0441, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0442, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0443, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0444, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0445, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0446, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0447, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0448, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0449, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0450, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0451, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0452, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0453, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0454, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0455, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0456, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0457, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0458, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0459, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0460, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0461, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0462, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0463, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0464, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0465, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0466, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0467, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0468, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0469, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0470, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0471, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0472, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0473, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0474, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0475, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0476, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0477, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0478, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0479, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0480, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0481, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0482, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0483, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0484, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0485, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0486, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0487, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0488, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0489, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0490, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0491, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0492, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0493, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0494, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0495, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0496, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0497, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0498, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0499, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0500, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0501, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0502, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0503, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0504, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0505, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0506, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0507, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0508, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0509, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0510, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0511, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0512, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0513, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0514, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0515, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0516, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0517, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0518, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0519, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0520, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0521, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0522, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0523, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0524, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0525, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0526, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0527, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0528, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0529, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0530, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0531, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0532, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0533, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0534, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0535, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0536, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0537, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0538, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0539, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0540, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0541, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0542, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0543, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0544, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0545, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0546, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0547, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0548, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0549, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0550, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0551, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0552, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0553, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0554, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0555, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0556, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0557, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0558, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0559, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0560, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0561, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0562, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0563, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0564, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0565, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0566, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0567, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0568, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0569, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0570, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0571, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0572, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0573, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0574, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0575, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0576, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0577, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0578, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0579, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0580, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0581, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0582, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0583, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0584, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0585, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0586, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0587, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0588, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0589, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0590, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0591, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0592, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0593, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0594, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0595, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0596, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0597, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0598, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0599, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0600, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0601, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0602, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0603, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0604, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0605, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0606, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0607, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0608, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0609, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0610, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0611, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0612, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0613, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0614, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0615, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0616, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0617, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0618, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0619, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0620, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0621, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0622, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0623, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0624, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0625, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0626, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0627, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0628, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0629, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0630, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0631, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0632, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0633, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0634, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0635, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0636, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0637, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0638, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0639, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0640, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0641, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0642, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0643, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0644, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0645, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0646, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0647, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0648, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0649, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0650, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0651, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0652, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0653, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0654, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0655, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0656, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0657, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0658, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0659, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0660, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0661, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0662, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0663, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0664, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0665, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0666, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0667, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0668, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0669, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0670, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0671, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0672, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0673, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0674, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0675, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0676, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0677, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0678, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0679, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0680, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0681, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0682, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0683, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0684, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0685, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0686, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0687, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0688, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0689, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0690, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0691, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0692, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0693, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0694, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0695, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0696, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0697, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0698, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0699, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0700, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0701, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0702, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0703, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0704, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0705, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0706, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0707, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0708, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0709, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0710, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0711, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0712, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0713, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0714, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0715, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0716, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0717, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0718, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0719, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0720, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0721, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0722, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0723, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0724, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0725, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0726, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0727, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0728, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0729, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0730, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0731, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0732, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0733, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0734, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0735, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0736, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0737, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0738, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0739, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0740, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0741, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0742, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8456\n",
            "Epoch: 0743, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0744, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0745, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0746, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0747, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0748, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0749, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0750, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0751, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0752, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0753, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0754, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0755, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0756, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0757, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0758, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0759, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0760, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0761, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0762, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0763, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0764, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0765, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0766, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0767, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0768, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0769, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0770, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0771, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0772, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0773, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0774, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0775, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0776, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0777, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0778, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0779, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0780, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0781, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0782, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0783, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0784, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0785, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0786, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0787, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0788, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0789, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0790, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0791, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0792, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0793, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0794, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0795, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0796, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0797, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0798, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0799, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0800, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0801, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0802, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0803, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0804, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0805, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0806, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0807, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0808, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0809, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0810, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0811, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0812, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0813, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0814, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0815, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0816, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0817, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0818, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0819, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0820, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0821, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0822, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0823, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0824, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0825, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0826, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0827, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0828, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0829, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0830, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0831, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0832, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0833, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0834, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0835, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0836, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0837, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0838, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0839, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0840, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0841, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0842, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0843, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0844, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0845, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0846, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0847, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0848, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0849, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0850, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0851, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0852, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0853, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0854, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0855, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0856, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0857, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0858, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0859, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0860, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0861, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0862, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0863, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0864, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0865, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0866, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0867, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0868, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0869, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0870, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0871, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0872, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0873, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0874, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0875, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0876, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0877, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0878, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0879, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0880, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0881, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0882, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0883, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0884, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0885, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0886, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0887, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0888, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0889, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0890, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0891, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0892, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0893, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0894, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0895, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0896, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0897, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0898, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0899, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0900, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0901, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0902, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0903, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0904, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0905, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0906, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0907, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0908, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0909, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0910, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0911, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0912, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0913, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0914, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0915, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0916, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0917, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0918, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0919, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0920, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0921, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0922, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0923, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0924, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0925, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0926, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0927, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0928, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0929, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0930, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0931, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0932, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0933, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0934, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0935, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0936, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0937, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0938, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0939, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0940, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0941, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0942, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0943, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0944, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0945, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0946, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0947, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0948, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0949, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0950, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0951, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0952, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0953, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0954, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0955, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0956, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0957, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0958, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0959, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0960, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0961, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0962, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0963, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0964, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0965, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0966, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0967, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0968, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0969, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0970, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0971, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0972, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0973, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0974, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0975, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0976, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0977, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0978, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0979, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0980, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0981, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0982, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0983, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0984, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0985, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0986, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0987, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0988, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0989, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0990, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0991, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0992, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0993, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0994, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0995, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0996, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0997, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0998, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n",
            "Epoch: 0999, Trn_loss: 0.0009, Trn_acc: 0.9994, Val_acc: 0.8542, Test_acc: 0.8440\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from torch_geometric.datasets import Planetoid, WebKB\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class KanGNN(torch.nn.Module):\n",
        "    def __init__(self, in_feat, hidden_feat, out_feat, grid_feat, num_layers, use_bias=False):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.lin_in = nn.Linear(in_feat, hidden_feat, bias=use_bias)\n",
        "        self.lins = torch.nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            self.lins.append(NaiveFourierKANLayer(hidden_feat, hidden_feat, grid_feat, addbias=use_bias))\n",
        "        self.lins.append(nn.Linear(hidden_feat, out_feat, bias=False))\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = self.lin_in(x)\n",
        "        for layer in self.lins[:self.num_layers - 1]:\n",
        "            x = layer(spmm(adj, x))\n",
        "        x = self.lins[-1](x)\n",
        "        return x.log_softmax(dim=-1)\n",
        "\n",
        "def train(args, feat, adj, label, mask, model, optimizer):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(feat, adj)\n",
        "    pred, true = out[mask], label[mask]\n",
        "    loss = F.nll_loss(pred, true)\n",
        "    acc = int((pred.argmax(dim=-1) == true).sum()) / int(mask.sum())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return acc, loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval(args, feat, adj, model):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model(feat, adj)\n",
        "    pred = pred.argmax(dim=-1)\n",
        "    return pred\n",
        "\n",
        "class Args:\n",
        "    path = './data/'\n",
        "    name = 'Cora'\n",
        "    logger_path = 'logger/esm'\n",
        "    dropout = 0.0\n",
        "    hidden_size = 256\n",
        "    grid_size = 200\n",
        "    n_layers = 2\n",
        "    epochs = 1000\n",
        "    early_stopping = 100\n",
        "    seed = 42\n",
        "    lr = 5e-4\n",
        "\n",
        "args = Args()\n",
        "\n",
        "args.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "random.seed(args.seed)\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "transform = T.Compose([T.NormalizeFeatures(), T.GCNNorm(), T.ToSparseTensor()])\n",
        "\n",
        "print(f'run experiments on {args.name} dataset')\n",
        "\n",
        "if args.name in {'Cora', 'Pubmed'}:\n",
        "    dataset = Planetoid(args.path, args.name, transform=transform)[0]\n",
        "elif args.name in {'Cornell'}:\n",
        "    dataset = WebKB(args.path, args.name, transform=transform)[0]\n",
        "\n",
        "in_feat = dataset.num_features\n",
        "out_feat = max(dataset.y) + 1\n",
        "\n",
        "model = KanGNN(\n",
        "    in_feat=in_feat,\n",
        "    hidden_feat=args.hidden_size,\n",
        "    out_feat=out_feat,\n",
        "    grid_feat=args.grid_size,\n",
        "    num_layers=args.n_layers,\n",
        "    use_bias=False,\n",
        ").to(args.device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "adj = dataset.adj_t.to(args.device)\n",
        "feat = dataset.x.float().to(args.device)\n",
        "label = dataset.y.to(args.device)\n",
        "\n",
        "trn_mask, val_mask, tst_mask = random_disassortative_splits(label, out_feat)\n",
        "trn_mask, val_mask, tst_mask = trn_mask.to(args.device), val_mask.to(args.device), tst_mask.to(args.device)\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    trn_acc, trn_loss = train(args, feat, adj, label, trn_mask, model, optimizer)\n",
        "    pred = eval(args, feat, adj, model)\n",
        "    val_acc = int((pred[val_mask] == label[val_mask]).sum()) / int(val_mask.sum())\n",
        "    tst_acc = int((pred[tst_mask] == label[tst_mask]).sum()) / int(tst_mask.sum())\n",
        "\n",
        "    print(f'Epoch: {epoch:04d}, Trn_loss: {trn_loss:.4f}, Trn_acc: {trn_acc:.4f}, Val_acc: {val_acc:.4f}, Test_acc: {tst_acc:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}